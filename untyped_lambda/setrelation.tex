\section{Inductive Sets and Relations}


\paragraph{Set Notation}

A set is an unordered collection of objects. If the object $a$ is an element of the set
$A$ we write $a \in A$.

A set $A$ is a subset of set $B$ if all elements of the set $A$ are also
elements of the set $B$. The symbol $\subseteq$ is used to express the subset
relation. The operator $:=$ is used to express that something is valid by
definition. Therefore the subset relation is defined symbolically by
$A \subseteq B := \forall a\mathbin. a \in A \imp a \in B$. The statement
$A \subseteq B$ can always be replaced by its definition
$\forall a\mathbin. a \in A \imp a \in B$ and vice versa.

The double arrow $\imp$ is used to express implication. $p \imp q$ states the
assertion that having a proof of $p$ we can conclude $q$. The assertion $p
\imp q$ is proved by assuming $p$ and deriving the validity of $q$.




\paragraph{Rule Notation}

We have often several premises which are needed reach a conclusion. E.g. we
might have the assertion $p_1 \land p_2 \land \ldots \imp c$. Then we use the
rule notation $\ruleh{p_1, p_2, \ldots}{c}$ or $\rulev{p_1 \\ p_2\\
  \vdots}{c}$ to express the same fact. Evidently the order of the premises is
not important.

Variable in rules are universally quantified. Therefore we can state the
subset definition $\forall a\mathbin. a \in A \imp a \in B$. in rule notation more
compactly and better readable as $\ruleh{a \in A}{a \in B}$. It should be clear
from the context which symbols denote variables.


\paragraph{Inductive Definition of Sets}

Rules can be used to define sets inductively. The set of even numbers $E$ can be
defined by the two rules $0 \in E$ and $\ruleh {n \in E}{n+2 \in E}$. A set
defined by rules is the least set which satisfies the rules. The set $E$ of
even number must contain the number $0$ and with all numbers $n$ it contains
also the number $n+2$.

The fact that some object is an element of an inductively defined set must be
established by an arbitrarily long but finite sequence of applications of the
rules which define the set. A proof of $4 \in E$ consists of a proof of $0 \in
E$ by application of the first rule and then two applications of the second
rule to reach $2 \in E$ and $4 \in E$.






\paragraph{Rule Induction}

If we have the fact that an object is an element of some inductively defined
set then we can be sure that it is in the set because of one of the rules
which define the set.

This can be used to prove facts by rule induction. Suppose we want to prove
that some property $p$ is shared by all even numbers. We can express this
statement by the rule $\ruleh {n \in E}{p(n)}$. Note that variables in rules
are implicitly universally quantified, i.e. the rule expresses the statement
$\forall n \mathbin. n \in E \imp p(n)$.

It is possible to prove this statement by induction on $n \in E$. Such a proof
consists of a proof of the statement for each rule. In the case of even
numbers there are two rules.

For the first rule we have to prove the the number $0$ satisfies the property
$p(0)$.

For the second rule we assume that $n \in E$ because there is some other
number $m$ already in the set of even numbers $E$ and $n = m+2$. I.e. we have
to prove the goal $p(m+2)$ under the premise $m \in E$. Because of the premise
$m \in E$ we can assume the induction hypothesis $p(m)$. I.e. we can assume
$m \in E$ and $p(m)$ and derive the validity of $p(m+2)$.

If the proof succeeds for both rules we are allowed to conclude that the
property $p$ is satisfied by all even numbers.



\paragraph{Natural Number Induction}

It is not difficult to see that the usual law of induction on natural numbers
is just a special case of rule induction. We can define the set of natural
numbers inductively $\mathbb{N}$ by the rules
\begin{enumerate}
\item $0 \in \mathbb{N}$
\item $\ruleh{n \in \mathbb{N}} {n' \in \mathbb{N}}$
\end{enumerate}
where $n'$ denotes the successor of $n$ i.e. $3$ is just a shorthand for
$0'''$.

The usual induction law of natural numbers allows to prove a property $p$ for
all natural number by a proof of $p(0)$ and a proof of
$\forall n\mathbin. p(n) \imp p(n')$ which are exactly the requirements of a
proof by rule induction.





\paragraph{Grammar Notation}

In some cases it is convenient to define a set by a grammar. E.g. we can
define the set of natural numbers by all terms $n$ generated by the grammar
%
    $$ n ::= 0 \mid n'$$
%
i.e. we can use the corresponding induction law to prove
that all terms generated by the grammar satisfy a certain property.

This definition is just a special form of the definition of the set of natural
numbers $\mathbb{N}$ by the rules
\begin{enumerate}
\item $0 \in \mathbb{N}$
\item $\ruleh{n \in \mathbb{N}} {n' \in \mathbb{N}}$
\end{enumerate}






\paragraph{Relations}

n-ary relations are just sets of n-tuples. A binary relation $r$ over the sets
$A$ and $B$ is a subset of the cartesian product
$$
    r \subseteq A \times B.
$$ We use the notations $(a,b) \in r$, $r(a,b)$ and $a \to_r b$ to denote the
fact that the pair $(a,b)$ with $a \in A$ and $b \in B$ figure in the relation
$r$.

In this paper we need only endorelations i.e. binary relations where the
domain $A$ and the range $B$ of the relation are the same set.




\paragraph{Relation Closure}

As with sets, relations can be defined inductively.


% Transitive Closure
% --------------
\begin{definition} The \emph{transitive closure} $\rplus{r}$ of a relation $r$ is
  defined by the rules
  \begin{enumerate}
  \item $\ruleh {r(a,b)} {\rplus{r}(a,b)}$
  \item $\ruleh{\rplus{r}(a,b),\, r(b,c)}{\rplus{r}(a,c)}$
  \end{enumerate}
\end{definition}

The rules can be displayed graphically. The premises are marked blue and the
conclusion is marked red.

\begin{tikzpicture}
  \node (a0) at (0,0) {$a$};
  \node (b0) at (1,0) {$b$};

  \node (a) at (3,0) {$a$};
  \node (b) at (4,0) {$b$};
  \node (c) at (5,0) {$c$};

  \draw [->,blue] (a0) edge node[above]{$r$} (b0);
  \draw [->,red]   (a0) .. controls (0.25,1) and (0.75,1) .. node[above] {$r^+$} (b0);

  \path[->,blue] (a) edge node[above] {$r^+$} (b);
  \path[->,blue] (b) edge node[above] {$r$}    (c);
  \draw[->,red]   (a) .. controls (3.5,1) and (4.5,1) ..  node[above] {$r^+$}    (c);
\end{tikzpicture}







% Reflexive Transitive Closure
% ----------------------
\begin{definition} The \emph{reflexive transitive closure} $\rstar{r}$ of a relation $r$ is
  defined by the rules
  \begin{enumerate}
  \item $\rstar{r}(a,a)$
  \item $\ruleh{\rstar{r}(a,b), \, r(b,c)}{\rstar{r}(a,c)}$
  \end{enumerate}
\end{definition}

Graphical representation of the rules:

\begin{tikzpicture}
  \node (reflexive) at (0,0) {$a$};
  \node (a) at (2,0) {$a$};
  \node (b) at (3,0) {$b$};
  \node (c) at (4,0) {$c$};

  \path (reflexive) edge [loop above,red] node {$r^*$} (reflexive);

  \path[->,blue] (a) edge node[above] {$r^*$} (b);
  \path[->,blue] (b) edge node[above] {$r$}    (c);
  \draw[->,red]   (a) .. controls (2.5,1) and (3.5,1) ..  node[above] {$r^*$}    (c);
\end{tikzpicture}






% Equivalence Closure
% ----------------
\begin{definition} The \emph{equivalence closure} $\reqv{r}$ of a relation $r$ is
  defined by the rules
  \begin{enumerate}
  \item
    $\reqv{r}(a,a)$
  \item
    $\ruleh{
      \reqv{r}(a,b), \,   r(b,c)}
    {\reqv{r}(a,c)}$
  \item
    $\ruleh{\reqv{r}(a,b), \, r(c,b)} {\reqv{r}(a,c)}$
  \end{enumerate}
\end{definition}

Again a graphical representation of the rules:

\begin{tikzpicture}
  \node (a0) at (0,0) {$a$};
  \path (a0) edge [loop above,red] node {$r^\sim$} (a0);

  \node (a1) at (1,0) {$a$};
  \node (b1) at (2,0) {$b$};
  \node (c1) at (3,0) {$c$};
  \draw[->,blue] (a1) edge node[above]{$r^\sim$} (b1);
  \draw[->,blue] (b1) edge node[above]{$r$} (c1);
  \draw[->,red] (a1) .. controls (1.5,1) and (2.5,1) .. node [above]{$r^\sim$} (c1);

  \node (a2) at (4,0) {$a$};
  \node (b2) at (5,0) {$b$};
  \node (c2) at (6,0) {$c$};
  \draw[->,blue] (a2) edge node[above]{$r^\sim$} (b2);
  \draw[<-,blue] (b2) edge node[above]{$r$} (c2);
  \draw[->,red]   (a2) .. controls (4.5,1) and (5.5,1) .. node [above]{$r^\sim$} (c2);
\end{tikzpicture}



% Closures are increasing, monotonic and idempotent
% -----------------------------------------
\begin{theorem}
  All closures are increasing $r \subseteq r^c$, monotonic
  $r \subseteq s \imp r^c \subseteq s^c$ and idempotent $r^{cc} = r$ (where
  the superscript $c$ stands for $+$, $*$ or $\sim$).
  \begin{proof}  We give a proof for the reflexive transitive closure. The
    proofs for the other closures are similar.
    \begin{itemize}
    \item
      Increasing: Goal $r(a,b) \imp \rstar{r}(a,b)$. By rule 1 we get
      $\rstar{r}(a,a)$. The assumption $r(a,b)$ and rule 2 imply
      $\rstar{r}(a,b)$.
      %
    \item
      Monotonic: Goal $\ruleh{r \subseteq s, \, \rstar{r}(a,b)}
      {\rstar{s}(a,b)}$. Prove by induction on $\rstar{r}(a,b)$.
        \begin{enumerate}
        \item Case $a=b$. Goal $s^*(a,a)$. Trivial by reflexivity of $\rstar{s}$.
        \item
          Goal $s^*(a,c)$ assuming $r\subseteq s$ and $r^*(a,c)$ is valid
          because of rule 2. Premises $r^*(a,b)$ and $r(b,c)$. Induction
          hypothesis $s^*(a,b)$.
          \\
          $
          \begin{matrix}
            a  & \to_{\rstar{r}} & b   &  \to_r   & c \\
                &    \Downarrow_1 & &  \Downarrow_2\\
            a  & \to_{\rstar{s}} & b   &  \to_s  &  c
          \end{matrix}$.\\
          $\Downarrow_1$ is valid by the induction
          hypothesis. $\Downarrow_2$ is valid by $r \subseteq s$. From the
          last line and the rule 2 of the reflexive transitive closure we can
          conclude $\rstar{s}(a,c)$.
        \end{enumerate}
    \item
      Idempotent: The equality of the relations $r^{**} = r^*$ needs a proof
      of $r^{**} \subseteq r^*$ and a proof of $r^* \subseteq r^{**}$.
      \begin{itemize}
      \item $ r^* \subseteq r^{**}$ is valid because the
        closure is increasing.
      \item
        Goal $\ruleh{r^{**}(a,b)} {r^*(a,b)}$. Proof by induction on $r^{**}(a,b)$.
        \begin{enumerate}
        \item
          Case $a=b$. Goal $r^*(a,a)$. Trivial by reflexivity.
        \item
          Goal $r^*(a,c)$ assuming $r^{**}(a,c)$ is valid because of rule 2.
          Premises $r^{**}(a,b)$ and $r^*(b,c)$. Induction
          hypothesis $r^*(a,b)$.
          $
          \begin{matrix}
            a  & \to_{r^{**}} & b   &  \to_{r^*}   & c \\
                &    \Downarrow_1 & &  \Downarrow_2\\
            a  & \to_{r^*} & b   &     \to_{r^*}   &  c
          \end{matrix}$.
          $\Downarrow_1$ is valid by the induction
          hypothesis. $\Downarrow_2$ is trivial. $r^*$ is
          transitive. Therefore the last line implies $r^*(a,c)$.
        \end{enumerate}
      \end{itemize}
    \end{itemize}
  \end{proof}
\end{theorem}






\begin{theorem}
A relation $s$ which satisfies $r \subseteq s \subseteq r^c$ has the same closure
as $r$ i.e. $r^c = s^c$. Proof:
  \begin{itemize}
  \item $r^c \subseteq s^c$ by monotonicity.
  \item $s^c \subseteq r^c$: $s^c \subseteq r^{cc}$ by
    monotonicity and then use idempotence to conclude $s^c \subseteq r^c$.
  \end{itemize}
\end{theorem}





\paragraph{Terminal Elements}

\begin{definition}
  The set of \emph{terminal elements} $T_r$ of the relation $r$ is
  defined by the rule
  $$
  \ruleh{
    \begin{bmatrix}
      \ruleh {a\to b} {\perp}
    \end{bmatrix}}
  {a \in T_r}$$
%
  where $\perp$ is used to denote a contradiction and the square brackets $[$
  and $]$ around the rule above the line indicate that the variables not used
  outside the bracketed rule are universally quantified in the inner
  rule. I.e. in order to establish $a \in T_r$ we have to prove
  $\forall b \mathbin. \neglow a \to_r b$ or
  $\forall b\mathbin. a \to_r b \imp \perp$.
%
  Note that the scope of the universal quantification of the variable $a$
  spans the whole rule while the scope of the universal quantification of the
  variable $b$ is just the premise of the rule (i.e. the part above the line).
\end{definition}



\begin{theorem}
  \label{trivialpaths}
  A terminal element $a$ of a relation $r$ has only trivial outgoing paths:
  $\ruleh {a \in T_r, \, a \to_r^* b} {a = b}$.
  \begin{proof} By induction on $a \to_r^* b$.
    \begin{enumerate}
    \item
      Goal $a = a$. Trivial.
    \item
      Goal $a = c$ assuming that $a \to_r^* c$ is valid by rule 2. Premises
      $r^*(a,b)$ and $r(b,c)$. Induction hypothesis $a = b$. Therefore the
      second premise states $r(a,c)$ which contradicts the assumption $a \in T_r$.
    \end{enumerate}
  \end{proof}
\end{theorem}


\paragraph{Weakly Terminating Elements}

\begin{definition}
  $a$ is a \emph{(weakly) terminating element} of the relation $r$ if there
  is a path to a terminal element $b$ i.e. $a \to_r^* b$. The set of
  \emph{weakly terminating elements} $WT_r$ of the relation $r$ is defined by
  the rule $\ruleh{a \to_r^* b, \, b \in T_r} {a \in WT_r}$.
\end{definition}






\paragraph{Strongly Terminating Elements}

\begin{definition}
  An object $a$ is \emph{strongly terminating} with respect to the relation
  $r$ if all paths from $a$ end at some terminal element of $r$. We define the
  set of strongly terminating elements $ST_r$ of the relation $r$ by the rule
%
$$
   \ruleh
   {
     \begin{bmatrix}
       \ruleh {a \to_r b} {b \in ST_r}
     \end{bmatrix}
   }
   {a \in ST_r}
$$
\end{definition}

This definition might need some explanation to be understood correctly. Since
the premise of the rule is within brackets, all variables not occuring outside
the brackets are universally quantified within the brackets (here the variable
$b$).

The rule says that all objects $a$ where all successors $b$ with respect to
the relation are strongly terminating are strongly terminating as well. The
rule is trivially satisfied by all objects which have no successors i.e. all
terminal objects. If the relation $r$ has no terminal objects then there
are no initial objects which are strongly terminating.

If there are terminal elements then step by step strongly terminating objects
can be constructed by the rule that all successors of them must be strongly
terminating (or already terminal). For each constructed strongly terminating
object it is guaranteed that all paths starting from it must end within a finite
number of steps at some terminal object of the relation.




An object $a$ without successors with respect to the relation $r$ i.e. if
there are no $b$ with $a \to_r b$ satisfy the rule, because the premise is
satified vacuously. An object $a$ without successors is a terminal element by
definition. I.e. all terminal elements are strongly terminating.










\paragraph{Diamonds and Confluence}

In this section we define confluent relations. A relation is called confluent
if starting from some object following the relation on different paths of
arbitrary length there is always some other object where the two paths
meet. This intuitive definition is made precise in the following.

It turns out that confluence is a rather strong property of a relation. It
guarantees that
\begin{itemize}
\item all equivalent elements meet at some point
\item all paths to terminal elements end up at the same terminal
  element (i.e. terminal elements are unique)
\end{itemize}

First we define formally the diamond property of a relation. The diamond
property is intuitively a one step confluence.

\begin{definition}
A relation $r$ is a \emph{diamond} if for all $a$, $b$ and $c$ there exists a $d$
such that
$
  \begin{matrix}
    a & \to_r & b \\
    \downarrow_r & & \downarrow_r \\
    c & \to_r & \exists d
  \end{matrix}
$ holds.
\end{definition}

\noindent Note that we use the picture
$$\begin{matrix}
  a & \to_r & b \\
  \downarrow_r & & \downarrow_r \\
  c & \to_r & \exists d
\end{matrix}$$ to express the statement
$$\ruleh {a \to_r b, \, a \to_r c} {\exists d\mathbin. b\to_r d \land c\to_r
  d}.$$
%
The picture notation is more intuitive but not less precise because it can be
translated into the corresponding rule notation which can be translated
uniquely into a statement of predicate logic.

\begin{definition}
  A relation $r$ is \emph{confluent} if $\rstar{r}$ is a diamond.
\end{definition}

\begin{theorem} In a confluent relation $r$ all two $r$-equivalent elements
  meet at some common element in zero or more steps
  $
  \begin{matrix}
    a & \to_r^\sim & b \\
    & \searrow_r^* & \downarrow_r^*\\
    & & \exists c
  \end{matrix}
  $.
  \begin{proof}
    By induction on $a \to_r^\sim b$.
    \begin{enumerate}

    \item $a = b$. Trivial. Take $c = a$.

    \item
      Goal
      $\begin{matrix}
        a    & \to_r^\sim      & c                      \\
              & \searrow_r^* & \downarrow_r^*  \\
        & & \exists e
      \end{matrix}$
      where $a \to_r^\sim c$ is valid by rule 2. Premises $a \to_r^\sim b$
      and $b \to_r c$.
      Induction hypothesis
      $\begin{matrix}
        a    & \to_r^\sim      & b                      \\
              & \searrow_r^* & \downarrow_*  \\
        & & \exists d
      \end{matrix}$.\\
      Proof
      $\begin{matrix}
        a & \reqv\to & b & \to_r & c\\
        & \searrow_r^* & \downarrow_r^*  & & \downarrow_r^*\\
        & & \exists d & \to_r^* & \exists e
      \end{matrix}$.
      $d$ exists by induction hypothesis, $e$ exists by confluence.

    \item
      Goal
      $\begin{matrix}
        a    & \to_r^\sim      & c                      \\
              & \searrow_r^* & \downarrow_r^*  \\
        & & \exists e
      \end{matrix}$
      where $a \to_r^\sim c$ is valid by rule 3. Premises $a \to_r^\sim b$
      and $b \gets_r c$.
      Induction hypothesis
      $\begin{matrix}
        a    & \to_r^\sim      & b                      \\
              & \searrow_r^* & \downarrow_*  \\
        & & \exists d
      \end{matrix}$.\\
      Proof
      $\begin{matrix}
        a & \reqv\to & b & \gets_r & c\\
        & \searrow_r^* & \downarrow_r^*  & & \downarrow_r^*\\
        & & \exists d & \to_r^* & \exists e
      \end{matrix}$.
      $d$ exists by induction hypothesis, $e$ exists by confluence.
    \end{enumerate}
  \end{proof}
\end{theorem}


\begin{theorem}
  In a confluent relation all paths from the same object ending at some terminal
  object end at the same terminal object, i.e.
  $$\ruleh {a \to_r^* b, \, a \to_r^* c, \, b \in T_r, \, c \in T_r} {b = c}$$.

  \begin{proof}
    Suppose there are two terminal elements $b$ and $c$ with paths starting
    from the object $a$.
    By definition of confluence there must be a $d$ such that
    $\begin{matrix} a & \tostar & b \\
      \downarrow_* & & \downarrow_* \\
      c & \tostar & d
    \end{matrix}$ is valid. Since $b$ and $c$ are terminal objects by
    theorem~\ref{trivialpaths} there are only trivial outgoing paths from $b$
    and $c$ which implies that $b = c = d$ must be valid.
  \end{proof}
\end{theorem}


\begin{theorem}
  A diamond relation is confluent.
  \begin{proof}
    We prove this theorem in two steps.
    \begin{itemize}
    \item Lemma: Let $r$ be a diamond. Then
      $\begin{matrix}
        a                     &    \to_r^*    &    b \\
        \downarrow_r &                   & \downarrow_r \\
        c                     & \to_r^*       & \exists d
      \end{matrix}$ is valid.
      Proof by induction on $a \to_r^* b$.
      \begin{enumerate}
      \item
        Case $a = b$. Trivial, take $d=c$.
      \item
        Goal $\begin{matrix}
          a                     &    \to_r^*    &    c \\
          \downarrow_r &                   & \downarrow_r \\
          d                     & \to_r^*       & \exists f
        \end{matrix}$ where $a \to_r^* c$ is valid because of rule 2.
        Premises $a \to_r^* b$ and $b \to_r c$.
        Induction hypothesis
        $\begin{matrix}
          a                     &    \to_r^*    &    b \\
          \downarrow_r &                   & \downarrow_r \\
          d                     & \to_r^*       & \exists e
        \end{matrix}$.
        \\
        Proof:
        $\begin{matrix}
          a                     & \to_r^* & b                     & \to_r & c\\
          \downarrow_r &             & \downarrow_r &          & \downarrow_r\\
          d                     & \to_r^* & \exists e        & \to_r & \exists f
        \end{matrix}$. $e$ exists by the induction hypothesis, $f$ exists because
        $\to_r$ is a diamond.
      \end{enumerate}

    \item Theorem:  Let $r$ be a diamond. Then
      $\begin{matrix}
        a                     & \to_r^*     & b \\
        \downarrow_r^* &                 & \downarrow_r^* \\
        c                        & \to_r^*     & \exists d
      \end{matrix}$ is valid.
      Proof by induction on $a \to_r^* c$.
      \begin{enumerate}
      \item
        Case $a = b$. Trivial, take $d=c$.
      \item
        Goal
        $\begin{matrix}
          a                     & \to_r^*     & b \\
          \downarrow_r^* &                 & \downarrow_r^* \\
          d                        & \to_r^*     & \exists f
        \end{matrix}$ where $a \to_r^* d$ is valid because of rule 2.
        Premises $a \to_r^* c$ and $c \to_r d$.
        Induction hypothesis
        $\begin{matrix}
          a                     & \to_r^*     & b \\
          \downarrow_r^* &                 & \downarrow_r^* \\
          c                        & \to_r^*     & \exists e
        \end{matrix}$.
        \\
        Proof
        $\begin{matrix}
          a                        & \to_r^*  & b\\
          \downarrow_r^* &              & \downarrow_r^* \\
          c                        & \to_r^*  & \exists e  \\
          \downarrow_r    &              & \downarrow_r \\
          d                        & \to_r^*  & \exists f
        \end{matrix}$.
        $e$ exists by induction hypothesis, $f$ exists by the previous lemma.
      \end{enumerate}
    \end{itemize}
  \end{proof}
\end{theorem}
